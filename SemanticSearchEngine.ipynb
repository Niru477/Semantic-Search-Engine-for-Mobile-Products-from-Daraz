{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from sentence_transformers) (4.45.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from sentence_transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from sentence_transformers) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from sentence_transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from sentence_transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from sentence_transformers) (0.25.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from sentence_transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence_transformers) (0.20.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->sentence_transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\niru dhaubanjar\\anaconda3\\envs\\semantic\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'D:/Semantic_Search_Engine/Data/cleaned_dataset.csv')\n",
    "titles = df['title'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OnePlus Nord CE 3 5G | 12GB RAM and 256GB ROM | 6.7 inch Fluid AMOLED 120 Hz Display | 80W SuperVOOC Charge',\n",
       "       'OnePlus Nord CE3 5G |12GB RAM, 256 GB Storage | Snapdragonâ„¢ 782G | 80W SUPERVOOC Charge | 17.02cm 120 Hz Fluid AMOLED + Dual Speakers',\n",
       "       'OnePlus Nord N30SE 5G | 4GB RAM, 128GB Storage | 5000 mAh Battery',\n",
       "       'Benco S1 (8GB+128GB) || Fingerprint || 48MP + 2MP + AI Camera || 5000Mah Battery',\n",
       "       'OnePlus Nord N30SE 5G (4/128GB) | 6.72\" FHD+ Sunlight Display | 5000 mAh Battery',\n",
       "       'Apple iPhone 15 Pro Max - EvoStore',\n",
       "       'Tecno Spark 20 Pro+ (16*/256 GB) | 6.78\" FHD + AMOLED Curved Screen | 120Hz Refresh Rate | 100 Days Replacement Warranty | G99 Ultra Boost Processor | 108MP Ultra Sensing Main Camera | 5000mAh Battery | 33W Super Charge',\n",
       "       'Oneplus Nord N30 SE 5G || 4/128 GB || 5000 mAh Battery',\n",
       "       'Oneplus Nord CE 3 5G || 12/256GB || Snapdragon 782G Chipset',\n",
       "       'Xiaomi Redmi 13C 4G LTE (4/128GB) | 6.74in Display | MediaTek Helio G85 processor | 5000mAh Battery',\n",
       "       'X-AGE SNAP Smartphone | 6GB/128GB | 48MP Rear Camera | 6.82\" IPS Display | UNISOC T606 | 5000mAh Battery',\n",
       "       'Infinix GT 20 Pro 5G (12/256GB) | 6.78\" Full HD+ 144Hz Amoled Display | MediaTek Dimensity 8200 ultimate 4nm 5G Processor | 5000mAh Battery | 45W Fast Charging',\n",
       "       'Samsung Galaxy A15 5G (6GB/128GB) | 6.5\" SuperAMOLED 90Hz Display | 50MP+5MP+2MP Rear Camera | 5000mAh Battery',\n",
       "       'Redmi 13C (4/128GB) | 6.74\" Dot Drop display | 90Hz Refresh Rate | 5000mAh Battery | 18W PD charging',\n",
       "       'Samsung Galaxy S24 Ultra 5G (12GB/512GB) | AI Smartphone | SnapDragon 8Gen 3 for Galaxy | 200MP Main Camera'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# title_embeddings = model.encode(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Niru Dhaubanjar\\anaconda3\\envs\\semantic\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\Niru Dhaubanjar\\anaconda3\\envs\\semantic\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Encoding titles: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:22<00:00,  1.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of title embeddings: (360, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the pre-trained BERT model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32  \n",
    "\n",
    "# Initialize a list to store the embeddings\n",
    "title_embeddings = []\n",
    "\n",
    "# Use tqdm to create a progress bar for batches\n",
    "for i in tqdm(range(0, len(titles), batch_size), desc=\"Encoding titles\", unit=\"batch\"):\n",
    "    # Get the current batch of titles\n",
    "    batch_titles = titles[i:i + batch_size]\n",
    "    \n",
    "    # Encode the batch of titles and handle any potential errors\n",
    "    try:\n",
    "        embeddings = model.encode(batch_titles, show_progress_bar=False)\n",
    "        # Append the embeddings to the list\n",
    "        title_embeddings.extend(embeddings)\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding titles {i} to {i + batch_size}: {e}\")\n",
    "\n",
    "# Convert the list to a numpy array for easier manipulation later\n",
    "title_embeddings = np.array(title_embeddings)\n",
    "\n",
    "# Output the shape of the embeddings to verify\n",
    "print(f\"Shape of title embeddings: {title_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embeddings to a file\n",
    "np.save('title_embeddings.npy', title_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import numpy as np\n",
    "\n",
    "# def search(query, title_embeddings, titles, df, top_n=5):\n",
    "#     \"\"\"\n",
    "#     Function to search for the most similar product titles.\n",
    "    \n",
    "#     Args:\n",
    "#     - query (str): Search query.\n",
    "#     - title_embeddings (ndarray): Precomputed embeddings of product titles.\n",
    "#     - titles (list): List of product titles.\n",
    "#     - df (DataFrame): Original DataFrame containing all product information.\n",
    "#     - top_n (int): Number of top results to return.\n",
    "    \n",
    "#     Returns:\n",
    "#     - List of tuples with product details and similarity scores.\n",
    "#     \"\"\"\n",
    "#     # Convert the search query into an embedding\n",
    "#     query_embedding = model.encode([query])\n",
    "\n",
    "#     # Compute cosine similarities between query and all product title embeddings\n",
    "#     similarities = cosine_similarity(query_embedding, title_embeddings)[0]\n",
    "\n",
    "#     # Get indices of top N most similar products\n",
    "#     top_indices = np.argsort(similarities)[::-1][:top_n]\n",
    "\n",
    "#     # Fetch product details from the original DataFrame for the top results\n",
    "#     results = []\n",
    "#     for idx in top_indices:\n",
    "#         product_info = {\n",
    "#             'title': df.iloc[idx]['title'],\n",
    "#             'price': df.iloc[idx]['price'],\n",
    "#             'rating': df.iloc[idx]['rating'],\n",
    "#             'sold': df.iloc[idx]['sold'],\n",
    "#             'offer': df.iloc[idx]['offer'],\n",
    "#             'link': df.iloc[idx]['full_link'],\n",
    "#             'similarity': similarities[idx]\n",
    "#         }\n",
    "#         results.append(product_info)\n",
    "\n",
    "#     return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def search(query, title_embeddings, titles, df, model, top_n=5):\n",
    "    \"\"\"\n",
    "    Function to search for the most similar product titles.\n",
    "    \n",
    "    Args:\n",
    "    - query (str): Search query.\n",
    "    - title_embeddings (ndarray): Precomputed embeddings of product titles.\n",
    "    - titles (list): List of product titles.\n",
    "    - df (DataFrame): Original DataFrame containing all product information.\n",
    "    - model: The model used to encode the query.\n",
    "    - top_n (int): Number of top results to return.\n",
    "    \n",
    "    Returns:\n",
    "    - List of product details with similarity scores or error message.\n",
    "    \"\"\"\n",
    "    # Convert the search query into an embedding\n",
    "    query_embedding = model.encode([query])\n",
    "\n",
    "    # Compute cosine similarities between query and all product title embeddings\n",
    "    similarities = cosine_similarity(query_embedding, title_embeddings)[0]\n",
    "\n",
    "    # Get indices of top N most similar products\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_n]\n",
    "\n",
    "    # Check if the highest similarity score is below the threshold\n",
    "    if similarities[top_indices[0]] < 0.45:\n",
    "        return {'error': 'No relevant results found for the given query.'}\n",
    "\n",
    "    # Fetch product details from the original DataFrame for the top results\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        product_info = {\n",
    "            'title': df.iloc[idx]['title'],\n",
    "            'price': df.iloc[idx]['price'],\n",
    "            'rating': df.iloc[idx]['rating'],\n",
    "            'sold': df.iloc[idx]['sold'],\n",
    "            'offer': df.iloc[idx]['offer'],\n",
    "            'link': df.iloc[idx]['full_link'],\n",
    "            'similarity': similarities[idx]\n",
    "        }\n",
    "        results.append(product_info)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: OnePlus Nord 2T 5G Mobile phone ( 6.43 inch fluid Amoled Display 80W SuperVOOC Charging )\n",
      "Price: 64999.0\n",
      "Rating: 2.0\n",
      "Sold Units: 12.0\n",
      "Offer: nan\n",
      "Product Link: https://www.daraz.com.np/products/oneplus-nord-2t-5g-mobile-phone-643-inch-fluid-amoled-display-80w-supervooc-charging-i114806947.html\n",
      "Similarity Score: 0.6551\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Q413 SMART PHONE\n",
      "Price: 5600.0\n",
      "Rating: 3.0\n",
      "Sold Units: 15.0\n",
      "Offer: 42% Off\n",
      "Product Link: https://www.daraz.com.np/products/q413-smart-phone-i129005432.html\n",
      "Similarity Score: 0.5689\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Q413 SMART PHONE\n",
      "Price: 5600.0\n",
      "Rating: 3.0\n",
      "Sold Units: 15.0\n",
      "Offer: 42% Off\n",
      "Product Link: https://www.daraz.com.np/products/q413-smart-phone-i129005432.html\n",
      "Similarity Score: 0.5689\n",
      "--------------------------------------------------------------------------------\n",
      "Title: ITEL A60s 4GB+4GB RAM 128GB Storage Mobile Smartphone\n",
      "Price: 12199.0\n",
      "Rating: nan\n",
      "Sold Units: 0.0\n",
      "Offer: 4% Off\n",
      "Product Link: https://www.daraz.com.np/products/itel-a60s-4gb4gb-ram-128gb-storage-mobile-smartphone-i131569720.html\n",
      "Similarity Score: 0.5632\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Samsung Galaxy A23 (6GB+128GB) With Selfie Stick, Mobile Cover & Earphone\n",
      "Price: 29999.0\n",
      "Rating: 16.0\n",
      "Sold Units: 87.0\n",
      "Offer: nan\n",
      "Product Link: https://www.daraz.com.np/products/samsung-galaxy-a23-6gb128gb-with-selfie-stick-mobile-cover-earphone-i113691620.html\n",
      "Similarity Score: 0.5301\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sample search query\n",
    "query = \"OnePlus 5G smartphone\"\n",
    "\n",
    "# Get the top 5 search results, assuming you have already defined `model`\n",
    "search_results = search(query, title_embeddings, titles, df, model)\n",
    "\n",
    "# Check if there's an error in the results\n",
    "if 'error' in search_results:\n",
    "    print(search_results['error'])\n",
    "else:\n",
    "    # Print the search results\n",
    "    for result in search_results:\n",
    "        print(f\"Title: {result['title']}\")\n",
    "        print(f\"Price: {result['price']}\")\n",
    "        print(f\"Rating: {result['rating']}\")\n",
    "        print(f\"Sold Units: {result['sold']}\")\n",
    "        print(f\"Offer: {result['offer']}\")\n",
    "        print(f\"Product Link: {result['link']}\")\n",
    "        print(f\"Similarity Score: {result['similarity']:.4f}\")\n",
    "        print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
